#!/usr/bin/env python3
"""
OpenCodeAT ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä½¿ç”¨ç‡å¯è¦–åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
åé›†ã—ãŸãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‹ã‚‰æ™‚ç³»åˆ—ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ
"""

import json
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple
import seaborn as sns

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šï¼ˆç’°å¢ƒã«å¿œã˜ã¦èª¿æ•´ï¼‰
plt.rcParams['font.sans-serif'] = ['DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class ContextVisualizer:
    """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä½¿ç”¨ç‡ã®å¯è¦–åŒ–"""
    
    def __init__(self, data_dir: Path = Path("telemetry/context_usage"),
                 output_dir: Path = Path("telemetry/visualization")):
        self.data_dir = data_dir
        self.output_dir = output_dir
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # ã‚«ãƒ©ãƒ¼ãƒ‘ãƒ¬ãƒƒãƒˆï¼ˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¿ã‚¤ãƒ—åˆ¥ï¼‰
        self.color_map = {
            'PM': '#FF6B6B',     # èµ¤ç³»
            'SE': '#4ECDC4',     # é’ç·‘ç³»
            'CI': '#45B7D1',     # é’ç³»
            'PG': '#96CEB4',     # ç·‘ç³»
            'CD': '#FECA57',     # é»„ç³»
            'ID': '#DDA0DD',     # ç´«ç³»
        }
        
        # ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š
        sns.set_style("whitegrid")
        plt.style.use('seaborn-v0_8-darkgrid')
    
    def load_all_metrics(self) -> pd.DataFrame:
        """ã™ã¹ã¦ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        all_data = []
        
        # JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿
        for json_file in self.data_dir.glob("metrics_*.json"):
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    
                    # context_usageãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
                    for entry in data.get('context_usage', []):
                        entry['timestamp'] = pd.to_datetime(entry['timestamp'])
                        all_data.append(entry)
            except Exception as e:
                print(f"Warning: Failed to load {json_file}: {e}")
        
        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚‚èª­ã¿è¾¼ã¿
        for csv_file in self.data_dir.glob("context_*.csv"):
            try:
                df = pd.read_csv(csv_file)
                df['timestamp'] = pd.to_datetime(df['timestamp'])
                all_data.extend(df.to_dict('records'))
            except Exception as e:
                print(f"Warning: Failed to load {csv_file}: {e}")
        
        if not all_data:
            print("No data found!")
            return pd.DataFrame()
        
        df = pd.DataFrame(all_data)
        df = df.sort_values('timestamp')
        
        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã‚’æŠ½å‡ºï¼ˆä¾‹: PG1.1.1 -> PGï¼‰
        df['agent_type'] = df['agent_id'].str.extract(r'^([A-Z]+)', expand=False)
        
        return df
    
    def plot_context_timeline(self, df: pd.DataFrame) -> Path:
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä½¿ç”¨ç‡ã®æ™‚ç³»åˆ—ã‚°ãƒ©ãƒ•"""
        fig, ax = plt.subplots(figsize=(14, 8))
        
        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã”ã¨ã«ãƒ—ãƒ­ãƒƒãƒˆ
        for agent_id in df['agent_id'].unique():
            agent_data = df[df['agent_id'] == agent_id]
            agent_type = agent_data['agent_type'].iloc[0] if len(agent_data) > 0 else 'OTHER'
            color = self.color_map.get(agent_type, '#888888')
            
            ax.plot(agent_data['timestamp'], 
                   agent_data['context_percentage'],
                   label=agent_id,
                   color=color,
                   linewidth=2,
                   marker='o',
                   markersize=4,
                   alpha=0.8)
        
        # å±é™ºã‚¾ãƒ¼ãƒ³ã®è¡¨ç¤º
        ax.axhspan(95, 100, alpha=0.3, color='red', label='Critical Zone (95-100%)')
        ax.axhspan(80, 95, alpha=0.2, color='orange', label='Alert Zone (80-95%)')
        ax.axhspan(60, 80, alpha=0.1, color='yellow', label='Warning Zone (60-80%)')
        
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆè¨­å®š
        ax.set_xlabel('Time', fontsize=12)
        ax.set_ylabel('Context Usage (%)', fontsize=12)
        ax.set_title('Claude Code Context Usage Timeline by Agent', fontsize=16, fontweight='bold')
        
        # Xè»¸ã®æ—¥æ™‚ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        ax.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d %H:%M'))
        ax.xaxis.set_major_locator(mdates.HourLocator(interval=1))
        plt.xticks(rotation=45)
        
        # å‡¡ä¾‹
        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)
        
        # ã‚°ãƒªãƒƒãƒ‰
        ax.grid(True, alpha=0.3)
        ax.set_ylim(0, 105)
        
        # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆèª¿æ•´
        plt.tight_layout()
        
        # ä¿å­˜
        output_file = self.output_dir / f"context_usage_timeline_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        plt.close()
        
        return output_file
    
    def plot_agent_comparison(self, df: pd.DataFrame) -> Path:
        """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆ¥ã®æœ€å¤§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä½¿ç”¨ç‡æ¯”è¼ƒ"""
        fig, ax = plt.subplots(figsize=(12, 8))
        
        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã”ã¨ã®æœ€å¤§ä½¿ç”¨ç‡ã‚’è¨ˆç®—
        max_usage = df.groupby('agent_id').agg({
            'context_percentage': 'max',
            'agent_type': 'first'
        }).reset_index()
        
        # ã‚½ãƒ¼ãƒˆ
        max_usage = max_usage.sort_values('context_percentage', ascending=True)
        
        # è‰²ã®è¨­å®š
        colors = [self.color_map.get(agent_type, '#888888') 
                 for agent_type in max_usage['agent_type']]
        
        # æ¨ªæ£’ã‚°ãƒ©ãƒ•
        bars = ax.barh(max_usage['agent_id'], 
                       max_usage['context_percentage'],
                       color=colors,
                       alpha=0.8,
                       edgecolor='black',
                       linewidth=1)
        
        # å€¤ã‚’ãƒãƒ¼ã®ç«¯ã«è¡¨ç¤º
        for i, bar in enumerate(bars):
            width = bar.get_width()
            ax.text(width + 0.5, bar.get_y() + bar.get_height()/2,
                   f'{width:.1f}%',
                   ha='left', va='center', fontsize=10)
        
        # å±é™ºãƒ©ã‚¤ãƒ³ã®è¡¨ç¤º
        ax.axvline(x=95, color='red', linestyle='--', alpha=0.7, label='Critical Threshold')
        ax.axvline(x=80, color='orange', linestyle='--', alpha=0.5, label='Alert Threshold')
        ax.axvline(x=60, color='yellow', linestyle='--', alpha=0.3, label='Warning Threshold')
        
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆè¨­å®š
        ax.set_xlabel('Maximum Context Usage (%)', fontsize=12)
        ax.set_ylabel('Agent ID', fontsize=12)
        ax.set_title('Maximum Context Usage by Agent', fontsize=16, fontweight='bold')
        ax.set_xlim(0, 105)
        
        # å‡¡ä¾‹
        ax.legend(loc='lower right')
        
        # ã‚°ãƒªãƒƒãƒ‰
        ax.grid(True, axis='x', alpha=0.3)
        
        # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆèª¿æ•´
        plt.tight_layout()
        
        # ä¿å­˜
        output_file = self.output_dir / f"agent_max_context_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        plt.close()
        
        return output_file
    
    def plot_token_distribution(self, df: pd.DataFrame) -> Path:
        """ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã®åˆ†å¸ƒ"""
        # ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ãƒ‡ãƒ¼ã‚¿ã‚’é›†è¨ˆ
        token_data = []
        
        # ã™ã¹ã¦ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ token_usage ã‚’åé›†
        for json_file in self.data_dir.glob("metrics_*.json"):
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    for entry in data.get('token_usage', []):
                        if entry['token_type'] in ['input', 'output']:
                            token_data.append({
                                'agent_id': entry['agent_id'],
                                'token_type': entry['token_type'],
                                'value': entry['value']
                            })
            except:
                continue
        
        if not token_data:
            print("No token data found for distribution plot")
            return None
        
        token_df = pd.DataFrame(token_data)
        
        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã‚’æŠ½å‡º
        token_df['agent_type'] = token_df['agent_id'].str.extract(r'^([A-Z]+)', expand=False)
        
        # é›†è¨ˆ
        summary = token_df.groupby(['agent_id', 'agent_type', 'token_type'])['value'].sum().unstack(fill_value=0)
        summary['total'] = summary.get('input', 0) + summary.get('output', 0)
        summary = summary.sort_values('total', ascending=True)
        
        # ãƒ—ãƒ­ãƒƒãƒˆ
        fig, ax = plt.subplots(figsize=(12, 8))
        
        # ã‚¹ã‚¿ãƒƒã‚¯æ¨ªæ£’ã‚°ãƒ©ãƒ•
        y_pos = range(len(summary))
        
        # Input tokens
        bars1 = ax.barh(y_pos, summary.get('input', 0), 
                        label='Input Tokens',
                        color='#3498db',
                        alpha=0.8)
        
        # Output tokens
        bars2 = ax.barh(y_pos, summary.get('output', 0), 
                        left=summary.get('input', 0),
                        label='Output Tokens',
                        color='#e74c3c',
                        alpha=0.8)
        
        # è¨­å®š
        ax.set_yticks(y_pos)
        ax.set_yticklabels(summary.index.get_level_values('agent_id'))
        ax.set_xlabel('Total Tokens', fontsize=12)
        ax.set_ylabel('Agent ID', fontsize=12)
        ax.set_title('Token Usage Distribution by Agent', fontsize=16, fontweight='bold')
        
        # å‡¡ä¾‹
        ax.legend(loc='lower right')
        
        # ã‚°ãƒªãƒƒãƒ‰
        ax.grid(True, axis='x', alpha=0.3)
        
        # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆèª¿æ•´
        plt.tight_layout()
        
        # ä¿å­˜
        output_file = self.output_dir / f"token_distribution_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        plt.close()
        
        return output_file
    
    def generate_summary_report(self, df: pd.DataFrame) -> Path:
        """ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
        report_file = self.output_dir / f"context_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("# OpenCodeAT Context Usage Summary Report\n\n")
            f.write(f"Generated at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}\n\n")
            
            # å…¨ä½“çµ±è¨ˆ
            f.write("## Overall Statistics\n\n")
            f.write(f"- Total data points: {len(df)}\n")
            f.write(f"- Monitoring period: {df['timestamp'].min()} to {df['timestamp'].max()}\n")
            f.write(f"- Number of agents: {df['agent_id'].nunique()}\n\n")
            
            # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆ¥çµ±è¨ˆ
            f.write("## Agent Statistics\n\n")
            f.write("| Agent ID | Type | Max Context % | Avg Context % | Last Context % | Data Points |\n")
            f.write("|----------|------|---------------|---------------|----------------|-------------|\n")
            
            for agent_id in sorted(df['agent_id'].unique()):
                agent_data = df[df['agent_id'] == agent_id]
                agent_type = agent_data['agent_type'].iloc[0]
                max_context = agent_data['context_percentage'].max()
                avg_context = agent_data['context_percentage'].mean()
                last_context = agent_data['context_percentage'].iloc[-1]
                data_points = len(agent_data)
                
                # å±é™ºåº¦ã«å¿œã˜ã¦å¼·èª¿
                if max_context > 95:
                    agent_id = f"**{agent_id}**"
                    status = " ğŸš¨"
                elif max_context > 80:
                    agent_id = f"**{agent_id}**"
                    status = " âš ï¸"
                elif max_context > 60:
                    status = " âš¡"
                else:
                    status = ""
                
                f.write(f"| {agent_id}{status} | {agent_type} | {max_context:.1f}% | "
                       f"{avg_context:.1f}% | {last_context:.1f}% | {data_points} |\n")
            
            # è­¦å‘Šäº‹é …
            critical_usage = df[df['context_percentage'] > 95]['agent_id'].unique()
            high_usage = df[(df['context_percentage'] > 80) & (df['context_percentage'] <= 95)]['agent_id'].unique()
            
            if len(critical_usage) > 0:
                f.write("\n## ğŸš¨ Critical Context Usage (>95%)\n\n")
                f.write("These agents need immediate attention:\n")
                for agent in critical_usage:
                    max_usage = df[df['agent_id'] == agent]['context_percentage'].max()
                    f.write(f"- **{agent}: {max_usage:.1f}%** - Auto-compact imminent\n")
            
            if len(high_usage) > 0:
                f.write("\n## âš ï¸ High Context Usage (80-95%)\n\n")
                f.write("These agents are approaching critical levels:\n")
                for agent in high_usage:
                    max_usage = df[df['agent_id'] == agent]['context_percentage'].max()
                    f.write(f"- {agent}: {max_usage:.1f}%\n")
            
            f.write("\n## Visualization Files\n\n")
            f.write("- Context usage timeline: `context_usage_timeline_*.png`\n")
            f.write("- Agent comparison: `agent_max_context_*.png`\n")
            f.write("- Token distribution: `token_distribution_*.png`\n")
        
        return report_file


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    visualizer = ContextVisualizer()
    
    print("Loading metrics data...")
    df = visualizer.load_all_metrics()
    
    if df.empty:
        print("No data available for visualization.")
        return
    
    print(f"Loaded {len(df)} data points from {df['agent_id'].nunique()} agents")
    
    # å¯è¦–åŒ–ã®ç”Ÿæˆ
    print("\nGenerating visualizations...")
    
    # 1. æ™‚ç³»åˆ—ã‚°ãƒ©ãƒ•
    timeline_file = visualizer.plot_context_timeline(df)
    print(f"âœ“ Context timeline saved to: {timeline_file}")
    
    # 2. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ¯”è¼ƒ
    comparison_file = visualizer.plot_agent_comparison(df)
    print(f"âœ“ Agent comparison saved to: {comparison_file}")
    
    # 3. ãƒˆãƒ¼ã‚¯ãƒ³åˆ†å¸ƒ
    token_file = visualizer.plot_token_distribution(df)
    if token_file:
        print(f"âœ“ Token distribution saved to: {token_file}")
    
    # 4. ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆ
    report_file = visualizer.generate_summary_report(df)
    print(f"âœ“ Summary report saved to: {report_file}")
    
    print("\nâœ… Visualization complete!")


if __name__ == "__main__":
    main()