#!/usr/bin/env python3

"""
VibeCodeHPC baÄŸlam (context) kullanÄ±m izleme sistemi
Claude Code JSONL gÃ¼nlÃ¼klerinden token kullanÄ±mÄ±nÄ± analiz eder ve Ã§eÅŸitli grafiklerle gÃ¶rselleÅŸtirir

Ã–zellikler:
1. agent_and_pane_id_table.jsonl dosyasÄ±ndan oturum IDâ€™lerini dinamik olarak alÄ±r
2. ~/.claude/projects/ altÄ±ndaki JSONL gÃ¼nlÃ¼klerini izler
3. usage bilgilerini Ã§Ä±karÄ±r ve toplam/akÃ¼mÃ¼lasyon token sayÄ±larÄ±nÄ± hesaplar
4. Ã‡eÅŸitli grafik tÃ¼rleriyle gÃ¶rselleÅŸtirir (yÄ±ÄŸÄ±lmÄ±ÅŸ Ã§ubuk, Ã§izgi, genel gÃ¶rÃ¼nÃ¼m)
5. auto-compact (~160K) iÃ§in Ã¶ngÃ¶rÃ¼
6. Hafif Ã¶nbellek sistemi (opsiyonel)
7. HÄ±zlÄ± durum (quick status) kontrolÃ¼
8. Zaman sÄ±nÄ±rÄ± seÃ§eneÄŸi (--max-minutes) ile grafik kapsamÄ±nÄ± kÄ±sÄ±tlama
"""

import json
import os
import sys
import subprocess
import platform
from pathlib import Path
from datetime import datetime, timezone, timedelta
import argparse
import matplotlib
matplotlib.use('Agg')  # GUI olmayan ortamlarda da Ã§alÄ±ÅŸÄ±r
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from collections import defaultdict, OrderedDict
from typing import Dict, List, Tuple, Optional
import numpy as np
import pickle
import gzip

# # Grafik stil ayarlarÄ±
try:
    plt.style.use('seaborn-v0_8-darkgrid')
except:
    plt.style.use('seaborn-darkgrid')
plt.rcParams['figure.figsize'] = (14, 10)
plt.rcParams['font.size'] = 10

class ContextUsageMonitor:
    """BaÄŸlam kullanÄ±m oranÄ± izleme sÄ±nÄ±fÄ±"""

    # Claude Code'un baÄŸlam sÄ±nÄ±rlamasÄ±
    
    # Claude Code baÄŸlam sÄ±nÄ±rÄ±
    CONTEXT_LIMIT = 200000  # 200K token (gÃ¶sterim amaÃ§lÄ±)
    AUTO_COMPACT_THRESHOLD = 160000  # GerÃ§ek auto-compact tetik noktasÄ± (tahmini)
    WARNING_THRESHOLD = 140000  # UyarÄ± eÅŸiÄŸi
    
    def __init__(self, project_root: Path, use_cache: bool = True, max_minutes: Optional[int] = None):
        """BaÄŸlam kullanÄ±m monitÃ¶rÃ¼nÃ¼ baÅŸlat"""
        self.claude_projects_dir = self._get_claude_projects_dir()
        self.output_dir = project_root / "User-shared" / "visualizations"
        # # Ã–nbellek ayarlarÄ±
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.max_minutes = max_minutes  # Zaman sÄ±nÄ±rÄ± (dakika)
        
        self.use_cache = use_cache
        self.cache_dir = project_root / ".cache" / "context_monitor"
        if self.use_cache:
            self.cache_dir.mkdir(parents=True, exist_ok=True)
    
    def _get_claude_projects_dir(self) -> Path:
        """TODO: Add docstring"""
        return Path.home() / ".claude" / "projects"
    
    def get_cache_path(self, agent_id: str, jsonl_file: Path) -> Path:
        """TODO: Add docstring"""
        cache_name = f"{agent_id}_{jsonl_file.stem}.pkl.gz"
        return self.cache_dir / cache_name
    
        # # DosyanÄ±n gÃ¼ncelleme zamanÄ±nÄ± karÅŸÄ±laÅŸtÄ±r
    def load_from_cache(self, cache_path: Path, jsonl_file: Path) -> Optional[List[Dict]]:
        """TODO: Add docstring"""
        if not self.use_cache or not cache_path.exists():
            return None  # JSONL daha yeni
            
        cache_mtime = cache_path.stat().st_mtime
        jsonl_mtime = jsonl_file.stat().st_mtime
        
        if jsonl_mtime > cache_mtime:
            return None  # JSONL daha yeni
            
        try:
            with gzip.open(cache_path, 'rb') as f:
                return pickle.load(f)
        except:
            return None
    
    def save_to_cache(self, cache_path: Path, data: List[Dict]):
        """TODO: Add docstring"""
        if not self.use_cache:
            return
            
        try:
            with gzip.open(cache_path, 'wb') as f:
                pickle.dump(data, f)
        except:
        # # Ajan bilgilerini yÃ¼kle
            pass  # Ã–nbelleÄŸe alma baÅŸarÄ±sÄ±zsa yoksay
    
    def find_project_jsonl_files(self) -> Dict[str, List[Path]]:
        """TODO: Add docstring"""
        agent_table_path = self.project_root / "Agent-shared" / "agent_and_pane_id_table.jsonl"
        
        if not agent_table_path.exists():
            print(f"âš ï¸  AracÄ± tablosu bulunamadÄ±: {agent_table_path}")
            return {}
        
        agent_info = {}
        with open(agent_table_path, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip() and not line.startswith('#'):
                    try:
                        data = json.loads(line)
                        if 'agent_id' in data and 'claude_session_id' in data:
                            agent_info[data['agent_id']] = {
        # # Platform tespiti ve yol dÃ¶nÃ¼ÅŸÃ¼mÃ¼
                                'session_id': data['claude_session_id'],
                                'working_dir': data.get('working_dir', ''),
        # # Her ajanÄ±n JSONL dosyasÄ±nÄ± ara
                                'cwd': data.get('cwd', '')  # Uyumluluk iÃ§in cwd de kontrol edilir
                            }
                    except json.JSONDecodeError:
                        continue
        
            # # working_dir veya cwd'ye gÃ¶re proje dizinini belirle
        if not agent_info:
            print("âš ï¸  agent_and_pane_id_table.jsonl iÃ§inde aracÄ± oturumu bulunamadÄ±")
                # # working_dir belirtilmiÅŸse
            return {}
        
                # # PM vb. durumlarda working_dir boÅŸsa
        print(f"ğŸ“Š Oturum IDâ€™si olan {len(agent_info)} aracÄ± bulundu")
        
            # # Yolu Claude projects dizin adÄ± olarak dÃ¶nÃ¼ÅŸtÃ¼r
            # # Claude Code dÃ¶nÃ¼ÅŸÃ¼m kurallarÄ± (deneylerle belirlenmiÅŸtir):
            # # - Alfabe ve rakamlar (a-zA-Z0-9) dÄ±ÅŸÄ±ndaki tÃ¼m karakterler '-' ile deÄŸiÅŸtirilir
            # # - Yol ayÄ±rÄ±cÄ± karakterler de '-' olarak dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r
            # # Ã–rnek: /mnt/c/Users/test_v1.0.0 -> -mnt-c-Users-test-v1-0-0
        system = platform.system()
            # # Ã–ncelikle yol ayÄ±rÄ±cÄ± karakterleri birleÅŸtir
        is_wsl = system == "Linux" and "microsoft" in platform.uname().release.lower()
                # Windows: Ters eÄŸik Ã§izgiyi eÄŸik Ã§izgiye dÃ¶nÃ¼ÅŸtÃ¼r
        
        agent_files = {}
        for agent_id, info in agent_info.items():
            if not info['session_id']:
            # # Alfabe ve rakamlar dÄ±ÅŸÄ±ndaki tÃ¼m karakterler (yol ayÄ±rÄ±cÄ±, Ã¶zel karakterler, boÅŸluk vb.) '-' ile deÄŸiÅŸtirilir
                continue
            
            # working_dir veya cwdâ€™ye gÃ¶re proje dizinini belirle
            working_dir = info['working_dir'] or info['cwd']
            
            if working_dir:
                # working_dir belirtilmiÅŸse
                full_path = self.project_root / working_dir
            else:
                full_path = self.project_root
            
            # Claude Code dÃ¶nÃ¼ÅŸtÃ¼rme kurallarÄ± (deneysel olarak saptandÄ±):
            # Ã–rn: /mnt/c/Users/test_v1.0.0 -> -mnt-c-Users-test-v1-0-0
            import re
                # Proje dizini bulunamazsa, benzer isimler aranÄ±r
            
            if system == "Windows":
                # Windows: ters eÄŸik Ã§izgileri eÄŸik Ã§izgiye dÃ¶nÃ¼ÅŸtÃ¼r
                path_str = str(full_path).replace('\\', '/')
            else:
                path_str = str(full_path)
            
            dir_name = re.sub(r'[^a-zA-Z0-9]', '-', path_str)
            
            project_dir = self.claude_projects_dir / dir_name
            if project_dir.exists():
                jsonl_file = project_dir / f"{info['session_id']}.jsonl"
        # # Ã–nbellek kontrolÃ¼
                if jsonl_file.exists():
                    if agent_id not in agent_files:
                        agent_files[agent_id] = []
            # # Zaman sÄ±nÄ±rÄ± ve last_n uygulanÄ±yor
                    agent_files[agent_id].append(jsonl_file)
                    print(f"  âœ… {agent_id}: Found log ({jsonl_file.stat().st_size / 1024:.1f} KB)")
                else:
                    print(f"  âš ï¸  {agent_id}: Session file not found: {jsonl_file.name}")
        # # Normal analiz iÅŸlemi
            else:
                similar_dirs = [d for d in self.claude_projects_dir.iterdir() 
                               if d.is_dir() and dir_name.lower() in d.name.lower()]
                if similar_dirs:
                    print(f"  âš ï¸  {agent_id}: Directory not found. Similar: {[d.name for d in similar_dirs[:3]]}")
                else:
                        # # Sadece usage alanÄ±na sahip girdiler
                    print(f"  âš ï¸  {agent_id}: Project dir not found: {dir_name}")
        
        return agent_files
    
    def parse_usage_data(self, jsonl_file: Path, agent_id: str, last_n: Optional[int] = None,
                        max_minutes: Optional[int] = None) -> List[Dict]:
        """JSONL dosyasÄ±ndan usage bilgilerini Ã§Ä±kar (Ã¶nbellek ve zaman sÄ±nÄ±rÄ± destekli)"""
        
        cache_path = self.get_cache_path(agent_id, jsonl_file)
        # # Ã–nbelleÄŸe kaydet
        cached_data = self.load_from_cache(cache_path, jsonl_file)
        # # Zaman sÄ±nÄ±rÄ± ve last_n uygulanÄ±yor
        if cached_data is not None:
            filtered_data = self._apply_time_filter(cached_data, max_minutes)
            if last_n and len(filtered_data) > last_n:
                return filtered_data[-last_n:]
            return filtered_data
        
        all_entries = []
        with open(jsonl_file, 'r') as f:
        # # Ä°lk zaman damgasÄ±nÄ± al
            for line in f:
                if line.strip():
                    try:
                        entry = json.loads(line)
                        if 'message' in entry and isinstance(entry['message'], dict):
                            msg = entry['message']
                            if 'usage' in msg and isinstance(msg['usage'], dict) and 'timestamp' in entry:
                                all_entries.append({
                                    'timestamp': entry['timestamp'],
                                    'usage': msg['usage']
        # # Zaman sÄ±nÄ±rÄ± ile filtreleme
                                })
                    except (json.JSONDecodeError, KeyError, TypeError):
                        continue
        
        self.save_to_cache(cache_path, all_entries)
        
        filtered_entries = self._apply_time_filter(all_entries, max_minutes)
        if last_n and len(filtered_entries) > last_n:
            return filtered_entries[-last_n:]
        return filtered_entries
    
    def _apply_time_filter(self, entries: List[Dict], max_minutes: Optional[int]) -> List[Dict]:
        """TODO: Add docstring"""
        if not max_minutes or not entries:
            return entries
        
        first_timestamp = None
        for entry in entries:
            try:
            # # Zaman damgasÄ± dÃ¶nÃ¼ÅŸÃ¼mÃ¼
                ts = datetime.fromisoformat(entry['timestamp'].replace('Z', '+00:00'))
                if first_timestamp is None or ts < first_timestamp:
                    first_timestamp = ts
                # # KÃ¼mÃ¼latif mod (geleneksel davranÄ±ÅŸ)
            except:
                continue
        
        if not first_timestamp:
            return entries
        
        filtered = []
        for entry in entries:
            try:
                ts = datetime.fromisoformat(entry['timestamp'].replace('Z', '+00:00'))
                elapsed_minutes = (ts - first_timestamp).total_seconds() / 60
                if elapsed_minutes <= max_minutes:
                # # AnlÄ±k gÃ¶rÃ¼ntÃ¼ modu (her anÄ±n context kullanÄ±mÄ±)
                    filtered.append(entry)
            except:
                continue
        
        return filtered
    
    def calculate_cumulative_tokens(self, usage_entries: List[Dict], cumulative: bool = False) -> List[Tuple[datetime, Dict[str, int]]]:
        """TODO: Add docstring"""
        token_data = []
        total_input = 0
        total_cache_creation = 0
        total_cache_read = 0
        total_output = 0
        
        for entry in usage_entries:
            ts = datetime.fromisoformat(entry['timestamp'].replace('Z', '+00:00'))
            
            usage = entry['usage']
            
            if cumulative:
            # # VarsayÄ±lan sayaÃ§ tabanlÄ± (token sayÄ±sÄ±nÄ±n belirtildiÄŸi loglar)
                total_input += usage.get('input_tokens', 0)
                total_cache_creation += usage.get('cache_creation_input_tokens', 0)
                total_cache_read += usage.get('cache_read_input_tokens', 0)
                total_output += usage.get('output_tokens', 0)
                
                token_data.append((ts, {
            # # Her ajan iÃ§in ayrÄ± grafik oluÅŸtur
                    'input': total_input,
                    'cache_creation': total_cache_creation,
                    'cache_read': total_cache_read,
                    'output': total_output,
                    'total': total_input + total_cache_creation + total_cache_read + total_output
                }))
            else:
                input_tokens = usage.get('input_tokens', 0)
                cache_creation = usage.get('cache_creation_input_tokens', 0)
        # # Uygun zamanlarda birden fazla grafik oluÅŸtur
                cache_read = usage.get('cache_read_input_tokens', 0)
        # # Belirtilen zaman sÄ±nÄ±rÄ± veya kilometre taÅŸÄ±nda oluÅŸtur
                output = usage.get('output_tokens', 0)
            # Kilometre taÅŸÄ± zamanÄ±nda, o zamana kadar grafik oluÅŸtur
                
                token_data.append((ts, {
                    'input': input_tokens,
            # # Kilometre taÅŸÄ± olmayan zaman belirtimi
                    'cache_creation': cache_creation,
                    'cache_read': cache_read,
            # # Zaman belirtilmemiÅŸse, genel ve kilometre taÅŸÄ± oluÅŸtur
            # # Genel grafik
                    'output': output,
            # # Proje baÅŸlangÄ±cÄ±ndan geÃ§en sÃ¼reyi kontrol et
                    'total': input_tokens + cache_creation + cache_read + output
                }))
                # Åimdiye kadarki geÃ§en sÃ¼reyi hesapla
            
        return token_data
    
    def generate_all_graphs(self, all_agent_data: Dict[str, List[Tuple[datetime, Dict[str, int]]]],
                    # # Sadece geÃ§en sÃ¼reyi aÅŸan kilometre taÅŸlarÄ±nÄ± oluÅŸtur
                           graph_type: str = 'all', time_unit: str = 'minutes', cumulative: bool = False):
        """Belirtilen tÃ¼rde grafikleri Ã¼ret"""
        self.is_cumulative = cumulative
        
        if graph_type in ['all', 'overview']:
            self.generate_overview_line_graph(all_agent_data, time_unit)
            
        if graph_type in ['all', 'stacked']:
        # # BaÅŸlÄ±kta zaman sÄ±nÄ±rÄ±nÄ± gÃ¶ster
            self.generate_stacked_bar_chart(all_agent_data, x_axis='count')
        # # Proje baÅŸlangÄ±Ã§ zamanÄ±nÄ± al
            self.generate_stacked_bar_chart(all_agent_data, x_axis='time')
            
        # # Sadece proje baÅŸlangÄ±Ã§ zamanÄ±ndan sonraki verileri filtrele
        if graph_type in ['all', 'timeline']:
            self.generate_timeline_graph(all_agent_data)
            
                # # max_minutes belirtilmiÅŸse, sadece bu aralÄ±ktaki verileri kullan
        if graph_type in ['all', 'individual']:
            for agent_id, cumulative_data in all_agent_data.items():
                if cumulative_data:
                    self.generate_agent_detail_graphs(agent_id, cumulative_data)
    
    def generate_overview_line_graph(self, all_agent_data: Dict[str, List[Tuple[datetime, Dict[str, int]]]], 
                                    time_unit: str = 'minutes'):
        """Genel gÃ¶rÃ¼nÃ¼m iÃ§in hafif Ã§izgi grafiÄŸi (basamak stili)
        
        Args:
        # # Her ajan iÃ§in toplam token sayÄ±sÄ±nÄ±n deÄŸiÅŸimi
            time_unit: 'seconds', 'minutes' veya 'hours' (varsayÄ±lan: 'minutes')
        """
        milestone_minutes = [30, 60, 90, 120, 180]
        
            # # GÃ¶reli zamana dÃ¶nÃ¼ÅŸtÃ¼r (varsayÄ±lan dakika cinsindendir)
        if self.max_minutes and self.max_minutes in milestone_minutes:
            self._generate_single_overview_graph(all_agent_data, time_unit, self.max_minutes)
        elif self.max_minutes:
            # # Basamak stilinde (merdiven ÅŸeklinde) Ã§izgi grafik
            self._generate_single_overview_graph(all_agent_data, time_unit, self.max_minutes)
        else:
        # # EÅŸik Ã§izgisi
            self._generate_single_overview_graph(all_agent_data, time_unit, None)
            
            project_start = self._get_project_start_time(all_agent_data)
            if project_start:
        # # X ekseni etiketi (birime gÃ¶re deÄŸiÅŸir)
                latest_time = max([t for data in all_agent_data.values() for t, _ in data]) if all_agent_data else None
                if latest_time:
        # # Y ekseni etiketi (kÃ¼mÃ¼latif modda deÄŸiÅŸir)
                    elapsed_minutes = (latest_time - project_start).total_seconds() / 60
                    
                    for milestone in milestone_minutes:
                        if elapsed_minutes >= milestone:
                            self._generate_single_overview_graph(all_agent_data, time_unit, milestone)
    
    def _generate_single_overview_graph(self, all_agent_data: Dict[str, List[Tuple[datetime, Dict[str, int]]]], 
                                       time_unit: str, max_minutes: Optional[int]):
        """Tek bir genel gÃ¶rÃ¼nÃ¼m grafiÄŸi Ã¼ret"""
        # # X ekseni aralÄ±ÄŸÄ±nÄ± zaman sÄ±nÄ±rÄ±na gÃ¶re ayarla
        plt.figure(figsize=(12, 8))
        
        title_suffix = f" (First {max_minutes} minutes)" if max_minutes else ""
        
        # # Dosya adÄ±na zaman sÄ±nÄ±rÄ±nÄ± dahil et
        project_start = self._get_project_start_time(all_agent_data)
            # Kilometre taÅŸÄ± zamanÄ±ysa Ã¶zel dosya adÄ±
        
        filtered_agent_data = {}
        if project_start:
            for agent_id, cumulative_data in all_agent_data.items():
                # max_minutes verilmiÅŸse o aralÄ±ktaki verileri kullan
                if max_minutes:
                    filtered_data = [(t, tokens) for t, tokens in cumulative_data 
                                   if t >= project_start and 
                                   (t - project_start).total_seconds() / 60 <= max_minutes]
                else:
                    filtered_data = [(t, tokens) for t, tokens in cumulative_data if t >= project_start]
                if filtered_data:
                    filtered_agent_data[agent_id] = filtered_data
        else:
            filtered_agent_data = all_agent_data
        
        for agent_id, cumulative_data in filtered_agent_data.items():
            if not cumulative_data:
                continue
                
            time_divisor = {'seconds': 1, 'minutes': 60, 'hours': 3600}[time_unit]
        # # Dosya yoksa tÃ¼m verilerin en eski zaman damgasÄ±nÄ± kullan
            times = [(t - project_start).total_seconds() / time_divisor for t, _ in cumulative_data]
            totals = [tokens['total'] for _, tokens in cumulative_data]
            
            plt.step(times, totals, where='post', marker='o', markersize=3, 
                    label=agent_id, alpha=0.8)
        
        plt.axhline(y=self.AUTO_COMPACT_THRESHOLD, color='red', 
                   linestyle='--', linewidth=2, label='Auto-compact (~160K)')
        plt.axhline(y=self.WARNING_THRESHOLD, color='orange', 
                   linestyle='--', linewidth=1, label='Warning (140K)')
        
        # # Renk haritasÄ± (statik â†’ dinamik sÄ±rasÄ±yla)
        unit_labels = {'seconds': 'Seconds', 'minutes': 'Minutes', 'hours': 'Hours'}
        plt.xlabel(f'{unit_labels[time_unit]} from Project Start')
        
        if hasattr(self, 'is_cumulative') and self.is_cumulative:
            plt.ylabel('Cumulative Token Usage')
            plt.title(f'Cumulative Token Usage Over Time{title_suffix}')
        else:
            plt.ylabel('Current Context Usage [tokens]')
            # # GÃ¼nlÃ¼k kayÄ±t sayÄ±sÄ±na dayalÄ± Ã§ubuk grafik
            plt.title(f'Context Usage Monitor{title_suffix}')
        plt.legend(loc='upper left', bbox_to_anchor=(1.02, 1))
        plt.grid(True, alpha=0.3)
        plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x/1000)}K'))
        
                # # En son veri noktasÄ±nÄ± kullan
        if max_minutes:
                # # X ekseni konumu
            plt.xlim(0, max_minutes)
        
                # # YÄ±ÄŸÄ±lmÄ±ÅŸ Ã§ubuk grafik (statik olandan)
        plt.tight_layout()
        
        if max_minutes:
            if max_minutes in [30, 60, 90, 120, 180]:
                output_path = self.output_dir / f"context_usage_{max_minutes}min.png"
            else:
                output_path = self.output_dir / f"context_usage_overview_{max_minutes}min.png"
                # # Toplam deÄŸeri Ã§ubuÄŸun Ã¼stÃ¼nde gÃ¶ster
        else:
            output_path = self.output_dir / "context_usage_overview.png"
        
        plt.savefig(output_path, dpi=120, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… Genel gÃ¶rÃ¼nÃ¼m grafiÄŸi oluÅŸturuldu: {output_path}")
    
    def _get_project_start_time(self, all_agent_data: Dict[str, List[Tuple[datetime, Dict[str, int]]]]) -> Optional[datetime]:
            # # Zaman tabanlÄ± yÄ±ÄŸÄ±lmÄ±ÅŸ alan grafiÄŸi
            # # En fazla token sayÄ±sÄ±na sahip ajanÄ± seÃ§
        """TODO: Add docstring"""
        start_time_file = self.project_root / "Agent-shared" / "project_start_time.txt"
        project_start = None
        
        if start_time_file.exists():
                # # Her token tÃ¼rÃ¼nÃ¼n deÄŸerini al
            try:
                # # YÄ±ÄŸÄ±lmÄ±ÅŸ alan grafiÄŸi
                with open(start_time_file, 'r') as f:
                    time_str = f.read().strip()
                    project_start = datetime.fromisoformat(time_str.replace('Z', '+00:00'))
            except:
                pass
        
        if project_start is None:
            for agent_data in all_agent_data.values():
                if agent_data and (project_start is None or agent_data[0][0] < project_start):
                    project_start = agent_data[0][0]
        
        # # Ortak ayarlar
        return project_start
    
    def generate_stacked_bar_chart(self, all_agent_data: Dict[str, List[Tuple[datetime, Dict[str, int]]]],
                                  x_axis: str = 'count'):
        """YÄ±ÄŸÄ±lmÄ±ÅŸ Ã§ubuk grafik (daha statik olanlar altta)"""
        fig, ax = plt.subplots(figsize=(16, 10))
        
        token_types = ['cache_read', 'cache_creation', 'input', 'output']
        token_colors = {
            'cache_read': '#f39c12',     # turuncu (en statik)
            'cache_creation': '#2ecc71',  # yeÅŸil
            'input': '#3498db',          # mavi
            'output': '#e74c3c'          # kÄ±rmÄ±zÄ± (en dinamik)
        }
        
        if x_axis == 'count':
            bar_width = 0.8
            agent_positions = {}
            
            for idx, (agent_id, cumulative_data) in enumerate(all_agent_data.items()):
        # # Ãœst kÄ±sÄ±m: TÃ¼m ajanlarÄ±n deÄŸiÅŸimi
                if not cumulative_data:
                    continue
                    
                latest_time, latest_tokens = cumulative_data[-1]
                
            # # Mevcut kullanÄ±m oranÄ±na gÃ¶re renk deÄŸiÅŸtir
                x_pos = idx
                agent_positions[agent_id] = x_pos
                
                bottom = 0
                for token_type in token_types:
                    value = latest_tokens[token_type]
                    ax.bar(x_pos, value, bar_width, bottom=bottom,
                          color=token_colors[token_type], 
                          label=token_type if idx == 0 else "")
                    bottom += value
                
                total = latest_tokens['total']
                percentage = (total / self.AUTO_COMPACT_THRESHOLD) * 100
                ax.text(x_pos, total + 2000, f'{total:,}\n({percentage:.1f}%)', 
                       ha='center', va='bottom', fontsize=9)
            
            ax.set_xticks(list(agent_positions.values()))
            ax.set_xticklabels(list(agent_positions.keys()))
            ax.set_xlabel('Agents')
            
        else:  # x_axis == 'time'
        # # Alt kÄ±sÄ±m: ArtÄ±ÅŸ oranÄ±nÄ±n gÃ¶rselleÅŸtirilmesi
            max_agent = max(all_agent_data.items(), 
                          key=lambda x: x[1][-1][1]['total'] if x[1] else 0)[0]
            
            if all_agent_data[max_agent]:
                data = all_agent_data[max_agent]
                times = [t for t, _ in data]
                
                token_values = {tt: [tokens[tt] for _, tokens in data] for tt in token_types}
                
        # # 1. Zaman serisi yÄ±ÄŸÄ±lmÄ±ÅŸ alan grafiÄŸi
                bottom = np.zeros(len(times))
                for token_type in token_types:
                    values = np.array(token_values[token_type])
        # # Renk haritasÄ± (statik â†’ dinamik sÄ±rasÄ±yla)
                    ax.fill_between(times, bottom, bottom + values, 
                                   color=token_colors[token_type],
                                   label=token_type, alpha=0.8)
                    bottom += values
                
                ax.set_xlabel('Time')
                ax.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d %H:%M'))
        # # Ãœst kÄ±sÄ±m: YÄ±ÄŸÄ±lmÄ±ÅŸ alan grafiÄŸi
                plt.xticks(rotation=45)
                ax.set_title(f'Token Usage Timeline - {max_agent}')
        
        ax.axhline(y=self.AUTO_COMPACT_THRESHOLD, color='red', 
                  linestyle='--', linewidth=2, label='Auto-compact (~160K)')
        ax.axhline(y=self.WARNING_THRESHOLD, color='orange', 
                  linestyle='--', linewidth=1, label='Warning (140K)')
        
        ax.set_ylabel('Cumulative Tokens')
        # # En son istatistik bilgisi
        ax.set_title(f'VibeCodeHPC Token Usage (X-axis: {x_axis})')
        ax.legend(loc='upper left', bbox_to_anchor=(1.02, 1))
        ax.grid(True, alpha=0.3, axis='y')
        # # EÅŸik Ã§izgisi
        ax.set_ylim(0, self.CONTEXT_LIMIT * 1.05)
        ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x/1000)}K'))
        
        plt.tight_layout()
        output_path = self.output_dir / f"context_usage_stacked_{x_axis}.png"
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… YÄ±ÄŸÄ±lmÄ±ÅŸ grafik oluÅŸturuldu ({x_axis} ekseni): {output_path}")
    
        # # Alt kÄ±sÄ±m: Her token tÃ¼rÃ¼nÃ¼n oran deÄŸiÅŸimi
    def generate_timeline_graph(self, all_agent_data: Dict[str, List[Tuple[datetime, Dict[str, int]]]]):
        """TODO: Add docstring"""
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10), 
                                       gridspec_kw={'height_ratios': [2, 1]})
        
        # # 2. Log sayÄ±sÄ± tabanlÄ± grafik
        for agent_id, cumulative_data in all_agent_data.items():
            if not cumulative_data:
                continue
                
            times = [t for t, _ in cumulative_data]
            totals = [tokens['total'] for _, tokens in cumulative_data]
            
        # # Her noktadaki oranÄ± hesapla
            current_usage = totals[-1] if totals else 0
            if current_usage >= self.AUTO_COMPACT_THRESHOLD * 0.95:
                color = 'red'
                alpha = 1.0
            elif current_usage >= self.WARNING_THRESHOLD:
                color = 'orange'
                alpha = 0.8
            else:
                color = 'blue'
        # # Oran deÄŸiÅŸimini Ã§iz
                alpha = 0.6
                
            ax1.step(times, totals, where='post', marker='o', markersize=3, 
                    label=f'{agent_id} ({current_usage/1000:.0f}K)', 
                    color=color, alpha=alpha)
        
        ax1.axhline(y=self.AUTO_COMPACT_THRESHOLD, color='red', 
                   linestyle='--', linewidth=2)
        ax1.set_ylabel('Total Tokens')
        ax1.set_title('Context Usage Timeline & Auto-compact Prediction')
        ax1.legend(loc='upper left', bbox_to_anchor=(1.02, 1))
        ax1.grid(True, alpha=0.3)
        ax1.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x/1000)}K'))
        
        # # X ekseni: Log giriÅŸ numarasÄ±
        self._plot_growth_rates(ax2, all_agent_data)
        
        # # Renk kodlamasÄ± (kullanÄ±m oranÄ±na gÃ¶re)
        plt.tight_layout()
        output_path = self.output_dir / "context_usage_timeline.png"
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… Zaman Ã§izelgesi grafiÄŸi oluÅŸturuldu: {output_path}")
    
    def generate_agent_detail_graphs(self, agent_id: str, cumulative_data: List[Tuple[datetime, Dict[str, int]]]):
        # # DaÄŸÄ±lÄ±m grafiÄŸi ve Ã§izgi
        """TODO: Add docstring"""
        
        # # EÅŸik Ã§izgisi
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10), 
                                       gridspec_kw={'height_ratios': [2, 1]})
        
        times = [t for t, _ in cumulative_data]
        
        token_types = ['cache_read', 'cache_creation', 'input', 'output']
        token_colors = {
            'cache_read': '#f39c12',     # turuncu
            'cache_creation': '#2ecc71',  # yeÅŸil
            'input': '#3498db',          # mavi
            'output': '#e74c3c'          # kÄ±rmÄ±zÄ±
        }
        
        token_values = {tt: [tokens[tt] for _, tokens in cumulative_data] for tt in token_types}
        bottom = np.zeros(len(times))
        
        for token_type in token_types:
            values = np.array(token_values[token_type])
            ax1.fill_between(times, bottom, bottom + values, 
                           color=token_colors[token_type],
                           label=token_type, alpha=0.8)
            bottom += values
        
            # # ArtÄ±ÅŸ oranÄ±nÄ± hesapla (token/saat)
        latest_tokens = cumulative_data[-1][1]
        total = latest_tokens['total']
        percentage = (total / self.AUTO_COMPACT_THRESHOLD) * 100
        
        ax1.axhline(y=self.AUTO_COMPACT_THRESHOLD, color='red', 
                   linestyle='--', linewidth=2, label='Auto-compact')
        ax1.axhline(y=self.WARNING_THRESHOLD, color='orange', 
                   linestyle='--', linewidth=1, label='Warning')
        
        ax1.set_ylabel('Cumulative Tokens')
        ax1.set_title(f'{agent_id} - Token Usage Detail ({total:,} tokens, {percentage:.1f}%)')
        ax1.legend(loc='upper left')
        ax1.grid(True, alpha=0.3)
        ax1.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x/1000)}K'))
        ax1.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d %H:%M'))
        
        self._plot_token_ratios(ax2, cumulative_data, token_types)
        
        plt.tight_layout()
        output_path = self.output_dir / f"context_usage_{agent_id}_detail.png"
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        self._generate_count_based_graph(agent_id, cumulative_data)
            # BaÅŸlÄ±k (kÃ¼mÃ¼latif modda deÄŸiÅŸir)
        
        print(f"âœ… {agent_id} iÃ§in bireysel grafik oluÅŸturma tamamlandÄ±")
    
    def _plot_token_ratios(self, ax, cumulative_data: List[Tuple[datetime, Dict[str, int]]], 
                          token_types: List[str]):
        """Token tÃ¼rlerinin oran seyrini Ã§iz"""
        times = [t for t, _ in cumulative_data]
        
        ratios = {tt: [] for tt in token_types}
        
            # # Ajan verilerini dÃ¼zenle
        for _, tokens in cumulative_data:
            total = tokens['total']
            if total > 0:
                for tt in token_types:
                    ratios[tt].append(100 * tokens[tt] / total)
            else:
                for tt in token_types:
                # # otomatik sÄ±kÄ±ÅŸtÄ±rmaya kadar tahmini sÃ¼re
                    ratios[tt].append(0)
        
                    # # Son artÄ±ÅŸ oranÄ±ndan tahmin
        for token_type in token_types:
            ax.plot(times, ratios[token_type], marker='o', markersize=3, 
                   label=f'{token_type} %', alpha=0.7)
        
        ax.set_xlabel('Time')
        ax.set_ylabel('Token Type Ratio (%)')
        ax.set_title('Token Type Distribution Over Time')
        ax.legend(loc='upper left', bbox_to_anchor=(1.02, 1))
        ax.grid(True, alpha=0.3)
                # # Durum simgesi (kÃ¼mÃ¼latif modda her zaman yeÅŸil)
        ax.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d %H:%M'))
        plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)
        ax.set_ylim(0, 100)
    
    def _generate_count_based_graph(self, agent_id: str, cumulative_data: List[Tuple[datetime, Dict[str, int]]]):
        """TODO: Add docstring"""
        fig, ax = plt.subplots(figsize=(12, 8))
        
        log_counts = list(range(1, len(cumulative_data) + 1))
        totals = [tokens['total'] for _, tokens in cumulative_data]
        
        colors = []
        for total in totals:
            if total >= self.AUTO_COMPACT_THRESHOLD * 0.95:
                colors.append('red')
            elif total >= self.WARNING_THRESHOLD:
                colors.append('orange')
            # # Token sayÄ±sÄ±na gÃ¶re sÄ±rala
            else:
                colors.append('blue')
        
        ax.scatter(log_counts, totals, c=colors, s=50, alpha=0.7, edgecolors='black')
        ax.plot(log_counts, totals, 'b-', alpha=0.3)
        
        ax.axhline(y=self.AUTO_COMPACT_THRESHOLD, color='red', 
                  linestyle='--', linewidth=2, label='Auto-compact')
        ax.axhline(y=self.WARNING_THRESHOLD, color='orange', 
                  linestyle='--', linewidth=1, label='Warning')
        
        ax.set_xlabel('Log Entry Count')
        ax.set_ylabel('Total Tokens')
        ax.set_title(f'{agent_id} - Token Usage by Log Count')
        ax.legend()
        ax.grid(True, alpha=0.3)
        ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x/1000)}K'))
        
        plt.tight_layout()
        output_path = self.output_dir / f"context_usage_{agent_id}_count.png"
        plt.savefig(output_path, dpi=120, bbox_inches='tight')
        plt.close()
    
    def _plot_growth_rates(self, ax, all_agent_data: Dict[str, List[Tuple[datetime, Dict[str, int]]]]):
        """TODO: Add docstring"""
        
        for agent_id, cumulative_data in all_agent_data.items():
            if len(cumulative_data) < 2:
                continue
                
            times = [t for t, _ in cumulative_data]
            totals = [tokens['total'] for _, tokens in cumulative_data]
            
            growth_rates = []
            growth_times = []
            
            for i in range(1, len(times)):
                time_diff = (times[i] - times[i-1]).total_seconds() / 3600  # Zaman birimi
                if time_diff > 0:
                    token_diff = totals[i] - totals[i-1]
                    rate = token_diff / time_diff
                    growth_rates.append(rate)
                    growth_times.append(times[i])
            
            if growth_rates:
                ax.plot(growth_times, growth_rates, marker='o', markersize=3, 
                       label=agent_id, alpha=0.7)
        
        # # AjanlarÄ± filtrele
        ax.set_xlabel('Time')
        ax.set_ylabel('Growth Rate (tokens/hour)')
        ax.set_title('Token Growth Rate Analysis')
        ax.legend(loc='upper left', bbox_to_anchor=(1.02, 1))
        ax.grid(True, alpha=0.3)
        ax.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d %H:%M'))
        plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)
    
        # # Tablo formatÄ±nda Ã§Ä±ktÄ±
    def generate_summary_report(self, all_agent_data: Dict[str, List[Tuple[datetime, Dict[str, int]]]]):
        """TODO: Add docstring"""
        # # Verileri dÃ¼zenle ve sÄ±rala
        report_path = self.output_dir / "context_usage_report.md"
        
        with open(report_path, 'w') as f:
            if hasattr(self, 'is_cumulative') and self.is_cumulative:
                f.write("# KÃ¼mÃ¼latif token kullanÄ±m raporu\n\n")
            else:
                f.write("# BaÄŸlam kullanÄ±m durumu raporu\n\n")
            
            # # Durum deÄŸerlendirmesi
            f.write(f"OluÅŸturulma zamanÄ±: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("## Ã–zet\n\n")
            f.write("| AracÄ± | Toplam [token] | KullanÄ±m oranÄ± | Cache Read | Cache Create | Input | Output | Tahmini sÃ¼re |\n")
            f.write("|-------|-----------------|----------------|------------|--------------|-------|--------|--------------|\n")
            
            # Ajan verilerini dÃ¼zenle
            # # Tahmini sÃ¼re
            agent_summaries = []
            
            for agent_id, cumulative_data in all_agent_data.items():
                if not cumulative_data:
                    continue
                    
                latest_time, latest_tokens = cumulative_data[-1]
                total = latest_tokens['total']
                percentage = (total / self.AUTO_COMPACT_THRESHOLD) * 100
                
                # auto-compact iÃ§in tahmini sÃ¼re
                est_hours = "N/A"
                if len(cumulative_data) >= 2:
                    # Son artÄ±ÅŸ oranÄ±ndan tahmin edilir
                    recent_data = cumulative_data[-min(10, len(cumulative_data)):]
                    time_span = (recent_data[-1][0] - recent_data[0][0]).total_seconds() / 3600
                    token_increase = recent_data[-1][1]['total'] - recent_data[0][1]['total']
                    
                    if time_span > 0 and token_increase > 0:
                        rate = token_increase / time_span
                        remaining_tokens = self.AUTO_COMPACT_THRESHOLD - total
                        if remaining_tokens > 0:
        # # Token sayÄ±sÄ±na gÃ¶re sÄ±rala
                            est_hours = f"{remaining_tokens / rate:.1f}h"
                
                # Durum simgesi (birikimli modda her zaman yeÅŸil)
                if hasattr(self, 'is_cumulative') and self.is_cumulative:
                    status = "ğŸŸ¢"  # KÃ¼mÃ¼latif modda eÅŸik deÄŸeri kontrolÃ¼ yoktur
                else:
                    if total >= self.AUTO_COMPACT_THRESHOLD * 0.95:
                        status = "ğŸ”´"
                    elif total >= self.WARNING_THRESHOLD:
                        status = "ğŸŸ¡"
                    else:
                        status = "ğŸŸ¢"
                
                agent_summaries.append({
                    'agent_id': agent_id,
                    'status': status,
                    'total': total,
    # # VarsayÄ±lan
                    'percentage': percentage,
                    'tokens': latest_tokens,
                    'est_hours': est_hours
                })
            
            # Token sayÄ±sÄ±na gÃ¶re sÄ±ralama
            agent_summaries.sort(key=lambda x: x['total'], reverse=True)
            
            for summary in agent_summaries:
                f.write(f"| {summary['status']} {summary['agent_id']} | "
                       f"{summary['total']:,} | "
                       f"{summary['percentage']:.1f}% | "
                       f"{summary['tokens']['cache_read']:,} | "
                       f"{summary['tokens']['cache_creation']:,} | "
                       f"{summary['tokens']['input']:,} | "
                       f"{summary['tokens']['output']:,} | "
                       f"{summary['est_hours']} |\n")
            
            f.write("\n## GÃ¶rselleÅŸtirmeler\n\n")
            f.write("### Global GÃ¶rÃ¼nÃ¼mler\n")
            f.write("- [Overview](context_usage_overview.png) - hafif Ã§izgi grafik\n")
            f.write("- [Stacked by Count](context_usage_stacked_count.png) - aracÄ± bazÄ±nda yÄ±ÄŸÄ±n\n")
            f.write("- [Stacked by Time](context_usage_stacked_time.png) - zaman serisi yÄ±ÄŸÄ±n\n")
            f.write("- [Timeline](context_usage_timeline.png) - tahmin ve trend analizi\n\n")
            
            f.write("### AracÄ± BazÄ±nda Detaylar\n")
            for agent_id in sorted(all_agent_data.keys()):
    # # Proje kÃ¶k dizinini al
                f.write(f"- {agent_id}: [Detay](context_usage_{agent_id}_detail.png) | "
                       f"[Adet](context_usage_{agent_id}_count.png)\n")
            
    # # Ã–nbelleÄŸi temizle
            f.write("\n## HÄ±zlÄ± EriÅŸim KomutlarÄ±\n\n")
            f.write("```bash\n")
            f.write("# En gÃ¼ncel durum (metin Ã§Ä±ktÄ±sÄ±)\n")
            f.write("python telemetry/context_usage_monitor.py --status\n\n")
            f.write("# Belirli aracÄ±nÄ±n durumunu gÃ¶rÃ¼ntÃ¼le\n")
            f.write("python telemetry/context_usage_monitor.py --status --agent PG1.1.1\n\n")
            f.write("# YalnÄ±zca Ã¶zet grafiÄŸi Ã¼ret (hafif)\n")
            f.write("python telemetry/context_usage_monitor.py --graph-type overview\n")
            f.write("```\n\n")
            
            f.write("## Cache Status\n\n")
            if self.use_cache and self.cache_dir.exists():
                cache_size = sum(f.stat().st_size for f in self.cache_dir.glob('*.pkl.gz'))
                f.write(f"- Cache directory: `.cache/context_monitor/`\n")
                f.write(f"- Total cache size: {cache_size / 1024 / 1024:.1f} MB\n")
        # # Her ajanÄ±n verilerini topla
                f.write(f"- Cache files: {len(list(self.cache_dir.glob('*.pkl.gz')))}\n")
            else:
                f.write("- Cache: Disabled\n")
        
            # # Birden fazla dosya varsa birleÅŸtir
        print(f"âœ… Rapor oluÅŸturma tamamlandÄ±: {report_path}")
    
    def print_quick_status(self, all_agent_data: Dict[str, List[Tuple[datetime, Dict[str, int]]]], 
                          target_agent: Optional[str] = None):
        """Konsola mevcut durumu yazdÄ±r (hÄ±zlÄ± eriÅŸim iÃ§in)"""
                # Zaman serisine gÃ¶re sÄ±rala
        
        print("\n" + "="*60)
        print(f"VibeCodeHPC Context Usage Status - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("="*60)
        
        # AjanlarÄ± filtreleme
        if target_agent:
                # # HÄ±zlÄ± durum gÃ¶sterimi
            filtered_data = {k: v for k, v in all_agent_data.items() 
                           if target_agent.upper() in k.upper()}
                # # Grafik ve rapor oluÅŸturma
        else:
            filtered_data = all_agent_data
        
        if not filtered_data:
            print(f"âŒ Agent '{target_agent}' not found")
    # # Ã‡alÄ±ÅŸtÄ±r
            return
        
        # Tablo formatÄ±nda Ã§Ä±ktÄ± verme
        print(f"{'Agent':<10} {'Total':>10} {'%':>6} {'Status':<8} {'Est.Time':<10}")
        print("-"*50)
        
        # Verileri dÃ¼zenle ve sÄ±rala
        agent_infos = []
        for agent_id, cumulative_data in filtered_data.items():
            if not cumulative_data:
    # # Gerekli paketlerin yÃ¼klÃ¼ olup olmadÄ±ÄŸÄ±nÄ± kontrol et
                continue
                
            latest_time, latest_tokens = cumulative_data[-1]
            total = latest_tokens['total']
            percentage = (total / self.AUTO_COMPACT_THRESHOLD) * 100
            
            # Durum belirleme
            if total >= self.AUTO_COMPACT_THRESHOLD * 0.95:
                status = "ğŸ”´ CRITICAL"
            elif total >= self.WARNING_THRESHOLD:
                status = "ğŸŸ¡ WARNING"
            else:
                status = "ğŸŸ¢ OK"
            
            # Tahmini sÃ¼re
            est_time = "N/A"
            if len(cumulative_data) >= 2:
                recent_data = cumulative_data[-min(10, len(cumulative_data)):]
                time_span = (recent_data[-1][0] - recent_data[0][0]).total_seconds() / 3600
                token_increase = recent_data[-1][1]['total'] - recent_data[0][1]['total']
                
                if time_span > 0 and token_increase > 0:
                    rate = token_increase / time_span
                    remaining_tokens = self.AUTO_COMPACT_THRESHOLD - total
                    if remaining_tokens > 0:
                        hours = remaining_tokens / rate
                        if hours < 1:
                            est_time = f"{int(hours*60)}min"
                        else:
                            est_time = f"{hours:.1f}h"
            
            agent_infos.append({
                'agent_id': agent_id,
                'total': total,
                'percentage': percentage,
                'status': status,
                'est_time': est_time
            })
        
        # Token sayÄ±sÄ±na gÃ¶re sÄ±ralama
        agent_infos.sort(key=lambda x: x['total'], reverse=True)
        
        # Ã‡Ä±ktÄ±
        for info in agent_infos:
            print(f"{info['agent_id']:<10} {info['total']:>10,} {info['percentage']:>5.1f}% "
                  f"{info['status']:<8} {info['est_time']:<10}")
        
        print("\n" + "="*60)

def get_python_command():
    """KullanÄ±labilir Python komutlarÄ±nÄ± al"""
    commands = ['python3', 'python']
    
    for cmd in commands:
        try:
            result = subprocess.run([cmd, '--version'], capture_output=True, text=True)
            if result.returncode == 0:
                return cmd
        except FileNotFoundError:
            continue
    
    # VarsayÄ±lan
    return 'python3'

def main():
    """Ana iÅŸlem"""
    parser = argparse.ArgumentParser(description='Monitor Claude Code context usage')
    parser.add_argument('--last-n', type=int, default=None,
                       help='Analyze only the last N log entries per agent')
    parser.add_argument('--graph-type', choices=['all', 'overview', 'stacked', 'timeline', 'individual'],
                       default='all', help='Type of graphs to generate')
    parser.add_argument('--time-unit', choices=['seconds', 'minutes', 'hours'],
                       default='minutes', help='Time unit for X-axis (default: minutes)')
    parser.add_argument('--cumulative', action='store_true',
                       help='Show cumulative token usage instead of per-request context size')
    parser.add_argument('--max-minutes', type=int, default=None,
                       help='Limit graph to first N minutes from project start (e.g., 60, 120, 180)')
    parser.add_argument('--no-cache', action='store_true',
                       help='Disable caching')
    parser.add_argument('--clear-cache', action='store_true',
                       help='Clear cache before running')
    parser.add_argument('--watch', action='store_true', 
                       help='Continue monitoring (update every 5 minutes)')
    parser.add_argument('--interval', type=int, default=300,
                       help='Update interval in seconds (default: 300)')
    parser.add_argument('--status', action='store_true',
                       help='Show quick status in console (no graphs)')
    parser.add_argument('--agent', type=str, default=None,
                       help='Show status for specific agent only')
    
    args = parser.parse_args()
    
    # Proje kÃ¶k dizinini alÄ±r
    project_root = Path(__file__).parent.parent
    monitor = ContextUsageMonitor(project_root, use_cache=not args.no_cache, max_minutes=args.max_minutes)
    
    # Ã–nbellek temizleme
    if args.clear_cache and monitor.cache_dir.exists():
        import shutil
        shutil.rmtree(monitor.cache_dir)
        monitor.cache_dir.mkdir(parents=True, exist_ok=True)
        print("âœ… Cache cleared")
    
    def update_once():
        """Sadece bir kez gÃ¼ncelle"""
        print("ğŸ” Scanning agent_and_pane_id_table.jsonl for session IDs...")
        jsonl_files = monitor.find_project_jsonl_files()
        
        if not jsonl_files:
            print("âŒ No JSONL files found for agents")
            print(f"   Check: {monitor.project_root / 'Agent-shared' / 'agent_and_pane_id_table.jsonl'}")
            return
        
        print(f"ğŸ“Š Found {len(jsonl_files)} agents with logs")
        
        # Her bir ajan iÃ§in verileri toplar
        all_agent_data = {}
        for agent_id, files in jsonl_files.items():
            if not args.status:  # Durum gÃ¶sterilirken ilerleme atlanÄ±r
                print(f"  - Processing {agent_id}...")
            
            # Birden fazla dosya varsa birleÅŸtirilecek
            all_usage_entries = []
            for jsonl_file in sorted(files):
                entries = monitor.parse_usage_data(jsonl_file, agent_id, args.last_n, args.max_minutes)
                all_usage_entries.extend(entries)
            
            if all_usage_entries:
                # Zaman serisine gÃ¶re sÄ±ralama
                all_usage_entries.sort(key=lambda x: x['timestamp'])
                cumulative_data = monitor.calculate_cumulative_tokens(all_usage_entries, args.cumulative)
                all_agent_data[agent_id] = cumulative_data
        
        if all_agent_data:
            if args.status:
                # HÄ±zlÄ± Durum GÃ¶rÃ¼ntÃ¼leme
                monitor.print_quick_status(all_agent_data, args.agent)
            else:
                # Grafik ve rapor oluÅŸturma
                monitor.generate_all_graphs(all_agent_data, args.graph_type, args.time_unit, args.cumulative)
                monitor.generate_summary_report(all_agent_data)
                print("âœ… Context usage monitoring complete")
        else:
            print("âŒ No usage data found in JSONL files")
    
    # Ã‡alÄ±ÅŸtÄ±rma
    if args.watch:
        import time
        print(f"ğŸ‘ï¸  Watching mode enabled (interval: {args.interval}s)")
        while True:
            update_once()
            print(f"ğŸ’¤ Waiting {args.interval}s...")
            time.sleep(args.interval)
    else:
        update_once()

if __name__ == "__main__":
    try:
        import matplotlib
        import numpy
        main()
    except ImportError:
        print("âŒ Error: Required packages not installed")
        print("Please install: pip3 install -r requirements.txt")
        sys.exit(1)
