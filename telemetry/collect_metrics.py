#!/usr/bin/env python3
"""
OpenCodeAT ãƒ†ãƒ¬ãƒ¡ãƒˆãƒªåé›†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Claude Codeã®OpenTelemetryã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›ã‚’è§£æã—ã€æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä¿å­˜
"""

import re
import json
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple

class MetricsCollector:
    """ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›ã‹ã‚‰ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’åé›†"""
    
    def __init__(self, output_dir: Path = Path("telemetry/context_usage")):
        self.output_dir = output_dir
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å®šç¾©
        self.patterns = {
            'token_usage': re.compile(
                r'claude_code\.token\.usage{.*?type="(input|output|cacheRead|cacheCreation)".*?agent_id="([^"]+)".*?} (\d+)'
            ),
            'session_id': re.compile(
                r'session\.id="([^"]+)"'
            ),
            'api_request': re.compile(
                r'event\.name="api_request".*?input_tokens=(\d+).*?output_tokens=(\d+).*?model="([^"]+)"'
            ),
            'timestamp': re.compile(
                r'timestamp="([^"]+)"'
            )
        }
        
        self.metrics_data = {
            'sessions': {},  # session_id -> agent_id ãƒãƒƒãƒ”ãƒ³ã‚°
            'token_usage': [],  # ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨å±¥æ­´
            'api_requests': [],  # APIãƒªã‚¯ã‚¨ã‚¹ãƒˆå±¥æ­´
            'context_usage': []  # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä½¿ç”¨ç‡å±¥æ­´
        }
    
    def parse_line(self, line: str) -> Optional[Dict]:
        """1è¡Œã‚’è§£æã—ã¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’æŠ½å‡º"""
        
        # ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã®æŠ½å‡º
        token_match = self.patterns['token_usage'].search(line)
        if token_match:
            token_type, agent_id, value = token_match.groups()
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã®æŠ½å‡º
            session_match = self.patterns['session_id'].search(line)
            session_id = session_match.group(1) if session_match else "unknown"
            
            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®æŠ½å‡ºï¼ˆãªã‘ã‚Œã°ç¾åœ¨æ™‚åˆ»ï¼‰
            timestamp_match = self.patterns['timestamp'].search(line)
            timestamp = timestamp_match.group(1) if timestamp_match else datetime.utcnow().isoformat()
            
            metric = {
                'timestamp': timestamp,
                'agent_id': agent_id,
                'session_id': session_id,
                'token_type': token_type,
                'value': int(value),
                'metric_type': 'token_usage'
            }
            
            self.metrics_data['token_usage'].append(metric)
            self.metrics_data['sessions'][session_id] = agent_id
            
            # inputãƒˆãƒ¼ã‚¯ãƒ³ã®å ´åˆã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä½¿ç”¨ç‡ã‚’è¨ˆç®—
            if token_type == 'input':
                context_usage = {
                    'timestamp': timestamp,
                    'agent_id': agent_id,
                    'session_id': session_id,
                    'tokens_used': int(value),
                    'context_percentage': (int(value) / 200000) * 100,
                    'metric_type': 'context_usage'
                }
                self.metrics_data['context_usage'].append(context_usage)
            
            return metric
        
        # APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¤ãƒ™ãƒ³ãƒˆã®æŠ½å‡º
        api_match = self.patterns['api_request'].search(line)
        if api_match:
            input_tokens, output_tokens, model = api_match.groups()
            
            timestamp_match = self.patterns['timestamp'].search(line)
            timestamp = timestamp_match.group(1) if timestamp_match else datetime.utcnow().isoformat()
            
            # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆIDã®æŠ½å‡º
            agent_match = re.search(r'agent_id="([^"]+)"', line)
            agent_id = agent_match.group(1) if agent_match else "unknown"
            
            api_metric = {
                'timestamp': timestamp,
                'agent_id': agent_id,
                'input_tokens': int(input_tokens),
                'output_tokens': int(output_tokens),
                'model': model,
                'metric_type': 'api_request'
            }
            
            self.metrics_data['api_requests'].append(api_metric)
            return api_metric
        
        return None
    
    def process_file(self, file_path: Path) -> Dict:
        """ãƒ•ã‚¡ã‚¤ãƒ«å…¨ä½“ã‚’å‡¦ç†"""
        metrics_count = 0
        
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                metric = self.parse_line(line)
                if metric:
                    metrics_count += 1
        
        return {
            'file': str(file_path),
            'metrics_collected': metrics_count,
            'summary': self.get_summary()
        }
    
    def get_summary(self) -> Dict:
        """åé›†ã—ãŸãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ã‚µãƒãƒªãƒ¼"""
        summary = {
            'total_sessions': len(self.metrics_data['sessions']),
            'total_token_metrics': len(self.metrics_data['token_usage']),
            'total_api_requests': len(self.metrics_data['api_requests']),
            'agents': {}
        }
        
        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆ¥ã®é›†è¨ˆ
        for agent_id in set(m['agent_id'] for m in self.metrics_data['token_usage']):
            agent_metrics = [m for m in self.metrics_data['token_usage'] if m['agent_id'] == agent_id]
            
            input_tokens = sum(m['value'] for m in agent_metrics if m['token_type'] == 'input')
            output_tokens = sum(m['value'] for m in agent_metrics if m['token_type'] == 'output')
            
            # æœ€æ–°ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä½¿ç”¨ç‡
            agent_context = [c for c in self.metrics_data['context_usage'] if c['agent_id'] == agent_id]
            latest_context = agent_context[-1]['context_percentage'] if agent_context else 0
            
            summary['agents'][agent_id] = {
                'input_tokens': input_tokens,
                'output_tokens': output_tokens,
                'total_tokens': input_tokens + output_tokens,
                'context_usage_percentage': latest_context,
                'metric_count': len(agent_metrics)
            }
        
        return summary
    
    def save_metrics(self, agent_id: str) -> Path:
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’JSONå½¢å¼ã§ä¿å­˜"""
        timestamp = datetime.utcnow().strftime('%Y%m%d_%H%M%S')
        output_file = self.output_dir / f"metrics_{agent_id}_{timestamp}.json"
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(self.metrics_data, f, indent=2, ensure_ascii=False)
        
        return output_file
    
    def save_context_usage_csv(self, agent_id: str) -> Path:
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä½¿ç”¨ç‡ã‚’CSVå½¢å¼ã§ä¿å­˜ï¼ˆå¯è¦–åŒ–ç”¨ï¼‰"""
        timestamp = datetime.utcnow().strftime('%Y%m%d_%H%M%S')
        csv_file = self.output_dir / f"context_{agent_id}_{timestamp}.csv"
        
        with open(csv_file, 'w', encoding='utf-8') as f:
            f.write("timestamp,agent_id,session_id,tokens_used,context_percentage\n")
            
            for entry in self.metrics_data['context_usage']:
                f.write(f"{entry['timestamp']},{entry['agent_id']},{entry['session_id']},"
                       f"{entry['tokens_used']},{entry['context_percentage']:.2f}\n")
        
        return csv_file


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    if len(sys.argv) < 2:
        print("Usage: python collect_metrics.py <input_file> [agent_id]")
        sys.exit(1)
    
    input_file = Path(sys.argv[1])
    agent_id = sys.argv[2] if len(sys.argv) > 2 else "unknown"
    
    if not input_file.exists():
        print(f"Error: File {input_file} not found")
        sys.exit(1)
    
    collector = MetricsCollector()
    
    print(f"Processing metrics from: {input_file}")
    result = collector.process_file(input_file)
    
    print("\nğŸ“Š Metrics Summary:")
    print(f"Total metrics collected: {result['metrics_collected']}")
    
    summary = result['summary']
    print(f"\nSessions: {summary['total_sessions']}")
    print(f"Token metrics: {summary['total_token_metrics']}")
    print(f"API requests: {summary['total_api_requests']}")
    
    print("\nğŸ‘¤ Agent Summary:")
    for agent, stats in summary['agents'].items():
        print(f"\nAgent: {agent}")
        print(f"  Input tokens: {stats['input_tokens']:,}")
        print(f"  Output tokens: {stats['output_tokens']:,}")
        print(f"  Total tokens: {stats['total_tokens']:,}")
        print(f"  Context usage: {stats['context_usage_percentage']:.2f}%")
    
    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ä¿å­˜
    json_file = collector.save_metrics(agent_id)
    csv_file = collector.save_context_usage_csv(agent_id)
    
    print(f"\nğŸ’¾ Saved metrics to:")
    print(f"  JSON: {json_file}")
    print(f"  CSV: {csv_file}")


if __name__ == "__main__":
    main()